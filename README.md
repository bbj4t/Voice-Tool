---
title: Voice Development Assistant
emoji: ğŸ¤
colorFrom: blue
colorTo: purple
sdk: gradio
sdk_version: "4.44.0"
app_file: app.py
pinned: true
license: mit
suggested_hardware: zero-a10g
suggested_storage: small
---

# ğŸ¤ Voice Development Assistant

A personal voice interface for development workflows featuring Speech-to-Text, Text-to-Speech, and Claude AI integration.

## âœ¨ Features

- ğŸ¤ **Speech-to-Text**: Real-time transcription using OpenAI Whisper (GPU accelerated with ZeroGPU)
- ğŸ”Š **Text-to-Speech**: Natural voice synthesis using OpenAI TTS (6 voice options)
- ğŸ¤– **Claude Integration**: Voice & text conversations with Claude AI
- ğŸ’¬ **Multi-Modal**: Switch between voice and text interaction seamlessly
- ğŸš€ **ZeroGPU**: Optimized for Hugging Face's H200 GPU cluster
- ğŸ’» **VS Code Extension**: Voice commands and dictation in your IDE
- âš™ï¸ **Configurable**: Swap between different TTS/STT providers

## ğŸ“ Project Structure

```
Voice-Tool/
â”œâ”€â”€ app.py                  # Main Gradio app (HF Spaces entry point)
â”œâ”€â”€ core/                   # Core voice services
â”‚   â”œâ”€â”€ stt_service.py     # Speech-to-text wrapper
â”‚   â”œâ”€â”€ tts_service.py     # Text-to-speech wrapper
â”‚   â””â”€â”€ voice_manager.py   # Voice coordination
â”œâ”€â”€ claude-bridge/          # Claude integration
â”‚   â”œâ”€â”€ api_client.py      # Claude API client
â”‚   â””â”€â”€ bridge_server.py   # WebSocket/HTTP server
â”œâ”€â”€ web-interface/          # Alternative web UI
â”‚   â””â”€â”€ app.py
â”œâ”€â”€ vscode-extension/       # VS Code integration
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ extension.js
â”œâ”€â”€ config/                 # Configuration
â”‚   â””â”€â”€ settings.yaml
â”œâ”€â”€ deployment/             # Deployment files
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ spaces_config.py
â”œâ”€â”€ Dockerfile              # Container deployment
â””â”€â”€ docker-compose.yml      # Local dev stack
```

## ğŸš€ Quick Start

### Option 1: Hugging Face Spaces (Recommended)

1. Fork this repository to your HuggingFace account
2. Create a new Space with Gradio SDK
3. Set secrets:
   - `ANTHROPIC_API_KEY`: Your Anthropic API key
   - `OPENAI_API_KEY`: Your OpenAI API key
4. Push and deploy!

### Option 2: Docker

```bash
# Clone the repo
git clone https://github.com/yourusername/Voice-Tool.git
cd Voice-Tool

# Create .env file
cp .env.example .env
# Edit .env with your API keys

# Run with Docker Compose
docker-compose up -d

# Access at http://localhost:7860
```

### Option 3: Local Development

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows

# Install dependencies
pip install -r deployment/requirements.txt

# Set environment variables
export ANTHROPIC_API_KEY="your_key"
export OPENAI_API_KEY="your_key"

# Run the app
python app.py
```

## ğŸ”§ Configuration

### Required API Keys

| Key | Required For | Get It From |
|-----|--------------|-------------|
| `ANTHROPIC_API_KEY` | Claude conversations | [console.anthropic.com](https://console.anthropic.com/) |
| `OPENAI_API_KEY` | Whisper STT & TTS | [platform.openai.com](https://platform.openai.com/) |

### Optional Configuration

Edit `config/settings.yaml` to customize:
- STT provider (whisper, deepgram, browser)
- TTS provider (openai, elevenlabs, coqui)
- Claude model and parameters
- Server ports

## ğŸ“– Usage

### Voice Chat
1. Click microphone to record
2. Speak your question
3. Claude responds with voice

### Transcription
- Upload audio or record via microphone
- GPU-accelerated Whisper transcription

### Text-to-Speech
- Enter text, choose voice
- Download generated audio

### Bridge Server (for integrations)
```bash
python claude-bridge/bridge_server.py
# HTTP API: http://localhost:8765
# WebSocket: ws://localhost:8766
```

## ğŸ”’ Privacy & Security

- No persistent data storage
- Session-only conversation history
- All API calls encrypted
- Open source - verify the code

## ğŸ“„ License

MIT License - Free for personal use
